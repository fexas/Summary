Using CUDA acceleration.
=== Step 1: Data Generation ===
Initialized GaussianTask with prior_type='uniform'
Generating training data (size=25600)...
Generating dataset (N=25600)...
Generating observation...
True Params: [ 1.   1.  -1.  -0.9  0.6]

=== Step 2: PyMC Reference Sampling ===
Inverted 3D obs to 2D for PyMC. Shape: (50, 2)
Setting up PyMC model for data shape (50, 2)...
Starting PyMC sampling...
                                                                                
                              Step      Grad      Sampli…                       
  Progre…   Draws   Diverg…   size      evals     Speed     Elapsed   Remaini…  
 ────────────────────────────────────────────────────────────────────────────── 
  ━━━━━━━   5000    0         0.54      7         524.57    0:00:09   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.68      3         546.53    0:00:09   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.67      7         528.78    0:00:09   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.50      3         519.68    0:00:09   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.59      7         269.22    0:00:18   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.75      7         267.74    0:00:18   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.63      7         270.40    0:00:18   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.59      7         261.41    0:00:19   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.58      7         178.96    0:00:27   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.65      3         178.35    0:00:28   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.61      3         176.47    0:00:28   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.53      7         172.07    0:00:29   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.56      7         133.66    0:00:37   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.56      7         132.01    0:00:37   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.53      7         132.72    0:00:37   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.60      7         129.72    0:00:38   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.59      7         106.52    0:00:46   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.64      7         105.81    0:00:47   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.49      3         106.28    0:00:47   0:00:00   
                                                  draws/s                       
  ━━━━━━━   5000    0         0.54      7         103.71    0:00:48   0:00:00   
                                                  draws/s                       
                                                                                

=== PyMC Diagnostics ===
           mean     sd  hdi_3%  hdi_97%  ...  mcse_sd  ess_bulk  ess_tail  r_hat
theta[0]  1.048  0.148   0.770    1.328  ...    0.001   33913.0   29724.0   1.00
theta[1]  0.887  0.139   0.620    1.145  ...    0.001   34337.0   29308.0   1.00
theta[2] -0.408  0.937  -1.119    1.087  ...    0.091      35.0     179.0   1.55
theta[3] -0.001  0.994  -1.080    1.072  ...    0.000      31.0     471.0   1.67
theta[4]  0.605  0.145   0.344    0.887  ...    0.001   31148.0   28786.0   1.00

[5 rows x 9 columns]
PyMC Samples Shape: (40000, 5)

=== Step 3: Run Model Experiments ===

=== Running Experiment for BAYESFLOW (Epochs=500) ===
Starting training (BayesFlow with Keras Loop)...
BayesFlow model built successfully.
Epoch [1/500], Loss: 10.0044
Epoch [2/500], Loss: 8.8397
Epoch [3/500], Loss: 7.6239
Epoch [4/500], Loss: 6.2252
Epoch [5/500], Loss: 5.6639
Epoch [6/500], Loss: 5.4566
Epoch [7/500], Loss: 5.2652
Epoch [8/500], Loss: 5.1907
Epoch [9/500], Loss: 5.0003
Epoch [10/500], Loss: 4.8807
Epoch [11/500], Loss: 4.6514
Epoch [12/500], Loss: 4.5155
Epoch [13/500], Loss: 4.3868
Epoch [14/500], Loss: 4.2272
Epoch [15/500], Loss: 4.1520
Epoch [16/500], Loss: 4.0919
Epoch [17/500], Loss: 3.9209
Epoch [18/500], Loss: 3.8277
Epoch [19/500], Loss: 3.7418
Epoch [20/500], Loss: 3.8059
Epoch [21/500], Loss: 3.6730
Epoch [22/500], Loss: 3.5129
Epoch [23/500], Loss: 3.4039
Epoch [24/500], Loss: 3.3954
Epoch [25/500], Loss: 3.2052
Epoch [26/500], Loss: 3.1159
Epoch [27/500], Loss: 3.0650
Epoch [28/500], Loss: 2.9827
Epoch [29/500], Loss: 2.8773
Epoch [30/500], Loss: 2.8646
Epoch [31/500], Loss: 2.8017
Epoch [32/500], Loss: 2.7188
Epoch [33/500], Loss: 2.6325
Epoch [34/500], Loss: 2.5716
Epoch [35/500], Loss: 2.5648
Epoch [36/500], Loss: 2.5327
Epoch [37/500], Loss: 2.4254
Epoch [38/500], Loss: 2.4419
Epoch [39/500], Loss: 2.3342
Epoch [40/500], Loss: 2.4023
Epoch [41/500], Loss: 2.3569
Epoch [42/500], Loss: 2.2511
Epoch [43/500], Loss: 2.1866
Epoch [44/500], Loss: 2.1848
Epoch [45/500], Loss: 2.1911
Epoch [46/500], Loss: 2.0389
Epoch [47/500], Loss: 2.0588
Epoch [48/500], Loss: 2.0022
Epoch [49/500], Loss: 1.9302
Epoch [50/500], Loss: 1.9598
Epoch [51/500], Loss: 1.9357
Epoch [52/500], Loss: 1.8128
Epoch [53/500], Loss: 1.8925
Epoch [54/500], Loss: 1.8373
Epoch [55/500], Loss: 1.7211
Epoch [56/500], Loss: 1.8098
Epoch [57/500], Loss: 1.7433
Epoch [58/500], Loss: 1.7811
Epoch [59/500], Loss: 1.7284
Epoch [60/500], Loss: 1.6655
Epoch [61/500], Loss: 1.6443
Epoch [62/500], Loss: 1.6000
Epoch [63/500], Loss: 1.6319
Epoch [64/500], Loss: 1.5894
Epoch [65/500], Loss: 1.5332
Epoch [66/500], Loss: 1.4851
Epoch [67/500], Loss: 1.5237
Epoch [68/500], Loss: 1.4666
Epoch [69/500], Loss: 1.4963
Epoch [70/500], Loss: 1.4367
Epoch [71/500], Loss: 1.4058
Epoch [72/500], Loss: 1.3824
Epoch [73/500], Loss: 1.4147
Epoch [74/500], Loss: 1.3956
Epoch [75/500], Loss: 1.4154
Epoch [76/500], Loss: 1.2955
Epoch [77/500], Loss: 1.3316
Epoch [78/500], Loss: 1.2861
Epoch [79/500], Loss: 1.3377
Epoch [80/500], Loss: 1.2955
Epoch [81/500], Loss: 1.3463
Epoch [82/500], Loss: 1.2647
Epoch [83/500], Loss: 1.2174
Epoch [84/500], Loss: 1.1839
Epoch [85/500], Loss: 1.1826
Epoch [86/500], Loss: 1.2293
Epoch [87/500], Loss: 1.1344
Epoch [88/500], Loss: 1.1571
Epoch [89/500], Loss: 1.0843
Epoch [90/500], Loss: 1.1220
Epoch [91/500], Loss: 1.1026
Epoch [92/500], Loss: 1.1485
Epoch [93/500], Loss: 1.1483
Epoch [94/500], Loss: 1.0693
Epoch [95/500], Loss: 1.0204
Epoch [96/500], Loss: 1.0692
Epoch [97/500], Loss: 1.0619
Epoch [98/500], Loss: 1.0318
Epoch [99/500], Loss: 1.0510
Epoch [100/500], Loss: 1.0183
Epoch [101/500], Loss: 0.9527
Epoch [102/500], Loss: 0.9446
Epoch [103/500], Loss: 1.0145
Epoch [104/500], Loss: 0.9230
Epoch [105/500], Loss: 0.9843
Epoch [106/500], Loss: 0.9027
Epoch [107/500], Loss: 1.0138
Epoch [108/500], Loss: 0.8798
Epoch [109/500], Loss: 0.8830
Epoch [110/500], Loss: 0.8998
Epoch [111/500], Loss: 0.9020
Epoch [112/500], Loss: 0.8728
Epoch [113/500], Loss: 0.9119
Epoch [114/500], Loss: 0.7940
Epoch [115/500], Loss: 0.8384
Epoch [116/500], Loss: 0.7691
Epoch [117/500], Loss: 0.8367
Epoch [118/500], Loss: 0.9124
Epoch [119/500], Loss: 0.7517
Epoch [120/500], Loss: 0.8037
Epoch [121/500], Loss: 0.8503
Epoch [122/500], Loss: 0.8059
Epoch [123/500], Loss: 0.7503
Epoch [124/500], Loss: 0.7709
Epoch [125/500], Loss: 0.8480
Epoch [126/500], Loss: 0.7508
Epoch [127/500], Loss: 0.7394
Epoch [128/500], Loss: 0.7163
Epoch [129/500], Loss: 0.6825
Epoch [130/500], Loss: 0.7554
Epoch [131/500], Loss: 0.6837
Epoch [132/500], Loss: 0.6595
Epoch [133/500], Loss: 0.7152
Epoch [134/500], Loss: 0.6239
Epoch [135/500], Loss: 0.7660
Epoch [136/500], Loss: 0.7185
Epoch [137/500], Loss: 0.7075
Epoch [138/500], Loss: 0.5768
Epoch [139/500], Loss: 0.6990
Epoch [140/500], Loss: 0.6143
Epoch [141/500], Loss: 0.7290
Epoch [142/500], Loss: 0.5983
Epoch [143/500], Loss: 0.6222
Epoch [144/500], Loss: 0.6747
Epoch [145/500], Loss: 0.6341
Epoch [146/500], Loss: 0.5899
Epoch [147/500], Loss: 0.5689
Epoch [148/500], Loss: 0.5739
Epoch [149/500], Loss: 0.5718
Epoch [150/500], Loss: 0.5428
Epoch [151/500], Loss: 0.5613
Epoch [152/500], Loss: 0.5341
Epoch [153/500], Loss: 0.6184
Epoch [154/500], Loss: 0.5595
Epoch [155/500], Loss: 0.5659
Epoch [156/500], Loss: 0.5481
Epoch [157/500], Loss: 0.4887
Epoch [158/500], Loss: 0.5638
Epoch [159/500], Loss: 0.5229
Epoch [160/500], Loss: 0.4928
Epoch [161/500], Loss: 0.5033
Epoch [162/500], Loss: 0.5046
Epoch [163/500], Loss: 0.4888
Epoch [164/500], Loss: 0.4683
Epoch [165/500], Loss: 0.5242
Epoch [166/500], Loss: 0.4658
Epoch [167/500], Loss: 0.4509
Epoch [168/500], Loss: 0.5059
Epoch [169/500], Loss: 0.4353
Epoch [170/500], Loss: 0.4201
Epoch [171/500], Loss: 0.4471
Epoch [172/500], Loss: 0.4316
Epoch [173/500], Loss: 0.4671
Epoch [174/500], Loss: 0.4036
Epoch [175/500], Loss: 0.3899
Epoch [176/500], Loss: 0.4274
Epoch [177/500], Loss: 0.4114
Epoch [178/500], Loss: 0.4281
Epoch [179/500], Loss: 0.4263
Epoch [180/500], Loss: 0.3736
Epoch [181/500], Loss: 0.3780
Epoch [182/500], Loss: 0.3163
Epoch [183/500], Loss: 0.3927
Epoch [184/500], Loss: 0.5330
Epoch [185/500], Loss: 0.3969
Epoch [186/500], Loss: 0.2882
Epoch [187/500], Loss: 0.3175
Epoch [188/500], Loss: 0.3436
Epoch [189/500], Loss: 0.2750
Epoch [190/500], Loss: 0.3262
Epoch [191/500], Loss: 0.3854
Epoch [192/500], Loss: 0.3004
Epoch [193/500], Loss: 0.2507
Epoch [194/500], Loss: 0.3270
Epoch [195/500], Loss: 0.3156
Epoch [196/500], Loss: 0.3349
Epoch [197/500], Loss: 0.3384
Epoch [198/500], Loss: 0.3067
Epoch [199/500], Loss: 0.2735
Epoch [200/500], Loss: 0.3228
Epoch [201/500], Loss: 0.3064
Epoch [202/500], Loss: 0.2968
Epoch [203/500], Loss: 0.2802
Epoch [204/500], Loss: 0.2890
Epoch [205/500], Loss: 0.2989
Epoch [206/500], Loss: 0.3195
Epoch [207/500], Loss: 0.2485
Epoch [208/500], Loss: 0.2727
Epoch [209/500], Loss: 0.2736
Epoch [210/500], Loss: 0.2884
Epoch [211/500], Loss: 0.2026
Epoch [212/500], Loss: 0.3138
Epoch [213/500], Loss: 0.2624
Epoch [214/500], Loss: 0.2768
Epoch [215/500], Loss: 0.2696
Epoch [216/500], Loss: 0.2800
Epoch [217/500], Loss: 0.2174
Epoch [218/500], Loss: 0.2807
Epoch [219/500], Loss: 0.1859
Epoch [220/500], Loss: 0.2205
Epoch [221/500], Loss: 0.2188
Epoch [222/500], Loss: 0.2242
Epoch [223/500], Loss: 0.1724
Epoch [224/500], Loss: 0.2526
Epoch [225/500], Loss: 0.1749
Epoch [226/500], Loss: 0.1826
Epoch [227/500], Loss: 0.2396
Epoch [228/500], Loss: 0.1621
Epoch [229/500], Loss: 0.1896
Epoch [230/500], Loss: 0.2574
Epoch [231/500], Loss: 0.1984
Epoch [232/500], Loss: 0.2478
Epoch [233/500], Loss: 0.1732
Epoch [234/500], Loss: 0.2162
Epoch [235/500], Loss: 0.1186
Epoch [236/500], Loss: 0.1793
Epoch [237/500], Loss: 0.1600
Epoch [238/500], Loss: 0.2432
Epoch [239/500], Loss: 0.1596
Epoch [240/500], Loss: 0.1031
Epoch [241/500], Loss: 0.1859
Epoch [242/500], Loss: 0.1418
Epoch [243/500], Loss: 0.0999
Epoch [244/500], Loss: 0.0882
Epoch [245/500], Loss: 0.1104
Epoch [246/500], Loss: 0.0978
Epoch [247/500], Loss: 0.1352
Epoch [248/500], Loss: 0.1034
Epoch [249/500], Loss: 0.1506
Epoch [250/500], Loss: 0.1092
Epoch [251/500], Loss: 0.1120
Epoch [252/500], Loss: 0.0552
Epoch [253/500], Loss: 0.1421
Epoch [254/500], Loss: 0.1519
Epoch [255/500], Loss: -0.0095
Epoch [256/500], Loss: 0.0481
Epoch [257/500], Loss: 0.1083
Epoch [258/500], Loss: 0.0738
Epoch [259/500], Loss: 0.1145
Epoch [260/500], Loss: 0.0758
Epoch [261/500], Loss: 0.0846
Epoch [262/500], Loss: 0.1332
Epoch [263/500], Loss: 0.1043
Epoch [264/500], Loss: 0.0511
Epoch [265/500], Loss: 0.0356
Epoch [266/500], Loss: 0.0836
Epoch [267/500], Loss: -0.0075
Epoch [268/500], Loss: 0.1003
Epoch [269/500], Loss: 0.0279
Epoch [270/500], Loss: -0.0092
Epoch [271/500], Loss: 0.0933
Epoch [272/500], Loss: 0.0008
Epoch [273/500], Loss: 0.0119
Epoch [274/500], Loss: 0.0773
Epoch [275/500], Loss: 0.0595
Epoch [276/500], Loss: 0.0818
Epoch [277/500], Loss: 0.0529
Epoch [278/500], Loss: 0.0449
Epoch [279/500], Loss: 0.0475
Epoch [280/500], Loss: -0.0223
Epoch [281/500], Loss: 0.0037
Epoch [282/500], Loss: 0.0306
Epoch [283/500], Loss: 0.0340
Epoch [284/500], Loss: 0.0212
Epoch [285/500], Loss: 0.0088
Epoch [286/500], Loss: -0.0456
Epoch [287/500], Loss: 0.0326
Epoch [288/500], Loss: -0.0531
Epoch [289/500], Loss: -0.0467
Epoch [290/500], Loss: 0.0158
Epoch [291/500], Loss: -0.0287
Epoch [292/500], Loss: 0.0257
Epoch [293/500], Loss: -0.0280
Epoch [294/500], Loss: 0.0290
Epoch [295/500], Loss: -0.0455
Epoch [296/500], Loss: -0.0205
Epoch [297/500], Loss: -0.0409
Epoch [298/500], Loss: -0.0431
Epoch [299/500], Loss: -0.0259
Epoch [300/500], Loss: -0.0744
Epoch [301/500], Loss: -0.1030
Epoch [302/500], Loss: -0.0232
Epoch [303/500], Loss: -0.0760
Epoch [304/500], Loss: -0.0671
Epoch [305/500], Loss: -0.0196
Epoch [306/500], Loss: -0.0758
Epoch [307/500], Loss: -0.0618
Epoch [308/500], Loss: -0.0111
Epoch [309/500], Loss: -0.1387
Epoch [310/500], Loss: -0.0406
Epoch [311/500], Loss: -0.0270
Epoch [312/500], Loss: -0.0405
Epoch [313/500], Loss: -0.0286
Epoch [314/500], Loss: -0.1028
Epoch [315/500], Loss: -0.1275
Epoch [316/500], Loss: -0.0042
Epoch [317/500], Loss: 0.0888
Epoch [318/500], Loss: -0.1289
Epoch [319/500], Loss: -0.0374
Epoch [320/500], Loss: -0.1891
Epoch [321/500], Loss: -0.0536
Epoch [322/500], Loss: -0.0920
Epoch [323/500], Loss: -0.0731
Epoch [324/500], Loss: -0.1378
Epoch [325/500], Loss: -0.1445
Epoch [326/500], Loss: -0.0684
Epoch [327/500], Loss: -0.0662
Epoch [328/500], Loss: -0.0889
Epoch [329/500], Loss: -0.1238
Epoch [330/500], Loss: -0.1712
Epoch [331/500], Loss: -0.1631
Epoch [332/500], Loss: -0.0573
Epoch [333/500], Loss: -0.1180
Epoch [334/500], Loss: -0.1942
Epoch [335/500], Loss: 0.1190
Epoch [336/500], Loss: -0.0966
Epoch [337/500], Loss: -0.1328
Epoch [338/500], Loss: -0.1438
Epoch [339/500], Loss: -0.1641
Epoch [340/500], Loss: -0.0970
Epoch [341/500], Loss: -0.1237
Epoch [342/500], Loss: -0.1328
Epoch [343/500], Loss: -0.2201
Epoch [344/500], Loss: -0.1426
Epoch [345/500], Loss: -0.1819
Epoch [346/500], Loss: -0.1076
Epoch [347/500], Loss: -0.1168
Epoch [348/500], Loss: -0.1595
Epoch [349/500], Loss: -0.1666
Epoch [350/500], Loss: -0.1459
Epoch [351/500], Loss: -0.1756
Epoch [352/500], Loss: -0.2043
Epoch [353/500], Loss: -0.1250
Epoch [354/500], Loss: -0.2044
Epoch [355/500], Loss: -0.1930
Epoch [356/500], Loss: -0.2065
Epoch [357/500], Loss: -0.2241
Epoch [358/500], Loss: -0.1413
Epoch [359/500], Loss: -0.2328
Epoch [360/500], Loss: -0.1669
Epoch [361/500], Loss: -0.2264
Epoch [362/500], Loss: -0.1614
Epoch [363/500], Loss: -0.1670
Epoch [364/500], Loss: -0.2069
Epoch [365/500], Loss: -0.1791
Epoch [366/500], Loss: -0.1804
Epoch [367/500], Loss: -0.2494
Epoch [368/500], Loss: -0.1998
Epoch [369/500], Loss: -0.2541
Epoch [370/500], Loss: -0.1803
Epoch [371/500], Loss: -0.2116
Epoch [372/500], Loss: -0.2060
Epoch [373/500], Loss: -0.2159
Epoch [374/500], Loss: -0.2925
Epoch [375/500], Loss: -0.2556
Epoch [376/500], Loss: -0.2548
Epoch [377/500], Loss: -0.2027
Epoch [378/500], Loss: -0.1967
Epoch [379/500], Loss: -0.2007
Epoch [380/500], Loss: -0.2853
Epoch [381/500], Loss: -0.2936
Epoch [382/500], Loss: 11.0344
Epoch [383/500], Loss: 8.3231
Epoch [384/500], Loss: 7.0104
Epoch [385/500], Loss: 6.1905
Epoch [386/500], Loss: 5.5754
Epoch [387/500], Loss: 5.1315
Epoch [388/500], Loss: 4.7581
Epoch [389/500], Loss: 4.4487
Epoch [390/500], Loss: 4.2073
Epoch [391/500], Loss: 3.9943
Epoch [392/500], Loss: 3.7893
Epoch [393/500], Loss: 3.6506
Epoch [394/500], Loss: 3.5362
Epoch [395/500], Loss: 3.3825
Epoch [396/500], Loss: 3.2148
Epoch [397/500], Loss: 3.1252
Epoch [398/500], Loss: 3.0629
Epoch [399/500], Loss: 2.9199
Epoch [400/500], Loss: 2.8002
Epoch [401/500], Loss: 2.7665
Epoch [402/500], Loss: 2.7273
Epoch [403/500], Loss: 2.5579
Epoch [404/500], Loss: 2.5438
Epoch [405/500], Loss: 2.4146
Epoch [406/500], Loss: 2.3868
Epoch [407/500], Loss: 2.3755
Epoch [408/500], Loss: 2.2349
Epoch [409/500], Loss: 2.2274
Epoch [410/500], Loss: 2.1499
Epoch [411/500], Loss: 2.1621
Epoch [412/500], Loss: 2.0985
Epoch [413/500], Loss: 2.0522
Epoch [414/500], Loss: 1.9923
Epoch [415/500], Loss: 1.9050
Epoch [416/500], Loss: 1.8905
Epoch [417/500], Loss: 1.8729
Epoch [418/500], Loss: 1.8427
Epoch [419/500], Loss: 1.7189
Epoch [420/500], Loss: 1.7779
Epoch [421/500], Loss: 1.6739
Epoch [422/500], Loss: 1.6620
Epoch [423/500], Loss: 2.0189
Epoch [424/500], Loss: 1.6883
Epoch [425/500], Loss: 1.5896
Epoch [426/500], Loss: 1.5516
Epoch [427/500], Loss: 1.4926
Epoch [428/500], Loss: 1.4545
Epoch [429/500], Loss: 1.5052
Epoch [430/500], Loss: 1.4088
Epoch [431/500], Loss: 1.4585
Epoch [432/500], Loss: 1.3280
Epoch [433/500], Loss: 1.2915
Epoch [434/500], Loss: 1.2655
Epoch [435/500], Loss: 1.2539
Epoch [436/500], Loss: 1.2057
Epoch [437/500], Loss: 1.2473
Epoch [438/500], Loss: 1.2533
Epoch [439/500], Loss: 1.1725
Epoch [440/500], Loss: 1.2442
Epoch [441/500], Loss: 1.1674
Epoch [442/500], Loss: 1.1028
Epoch [443/500], Loss: 1.0619
Epoch [444/500], Loss: 1.0289
Epoch [445/500], Loss: 1.0248
Epoch [446/500], Loss: 1.0787
Epoch [447/500], Loss: 1.0654
Epoch [448/500], Loss: 1.0073
Epoch [449/500], Loss: 0.9425
Epoch [450/500], Loss: 0.9734
Epoch [451/500], Loss: 0.9080
Epoch [452/500], Loss: 0.9743
Epoch [453/500], Loss: 0.9361
Epoch [454/500], Loss: 0.8548
Epoch [455/500], Loss: 0.9198
Epoch [456/500], Loss: 0.8847
Epoch [457/500], Loss: 0.8244
Epoch [458/500], Loss: 0.8268
Epoch [459/500], Loss: 0.8140
Epoch [460/500], Loss: 0.8168
Epoch [461/500], Loss: 0.8258
Epoch [462/500], Loss: 0.7397
Epoch [463/500], Loss: 0.7476
Epoch [464/500], Loss: 0.6908
Epoch [465/500], Loss: 0.6825
Epoch [466/500], Loss: 0.7329
Epoch [467/500], Loss: 0.6304
Epoch [468/500], Loss: 0.7137
Epoch [469/500], Loss: 0.6132
Epoch [470/500], Loss: 0.6611
Epoch [471/500], Loss: 0.6711
Epoch [472/500], Loss: 0.6851
Epoch [473/500], Loss: 0.6366
Epoch [474/500], Loss: 0.6349
Epoch [475/500], Loss: 0.6215
Epoch [476/500], Loss: 0.5599
Epoch [477/500], Loss: 0.5344
Epoch [478/500], Loss: 0.5715
Epoch [479/500], Loss: 0.5634
Epoch [480/500], Loss: 0.5618
Epoch [481/500], Loss: 0.5200
Epoch [482/500], Loss: 0.4555
Epoch [483/500], Loss: 0.4506
Epoch [484/500], Loss: 0.4836
Epoch [485/500], Loss: 0.5203
Epoch [486/500], Loss: 0.4506
Epoch [487/500], Loss: 0.4102
Epoch [488/500], Loss: 0.4270
Epoch [489/500], Loss: 0.4483
Epoch [490/500], Loss: 0.4583
Epoch [491/500], Loss: 0.3730
Epoch [492/500], Loss: 0.3702
Epoch [493/500], Loss: 0.4639
Epoch [494/500], Loss: 0.3843
Epoch [495/500], Loss: 0.3756
Epoch [496/500], Loss: 0.4312
Epoch [497/500], Loss: 0.3241
Epoch [498/500], Loss: 0.3364
Epoch [499/500], Loss: 0.3267
Epoch [500/500], Loss: 0.2811
Training finished in 4117.04s
--- Amortized Inference (bayesflow) ---
Posterior Mean: [ 1.3742921   0.92136697  0.11815734 -0.02465705  0.70942544]
--- Local Refinement (bayesflow) ---
Starting BayesFlow MCMC Refinement...
Computing bandwidth for BayesFlow refinement...
